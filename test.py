import streamlit as st
import torch
import numpy as np
from PIL import Image
import torchvision.transforms as transforms
from model import CNNLSTM_ImageRadFusion  # Kiáº¿n trÃºc mÃ´ hÃ¬nh má»›i
import os
import random
import numpy as np
import torch
from torchvision.models import resnet18
def set_seed(seed):
    """Sets the random seed for reproducibility."""
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False # Set to False for determinism
    # torch.use_deterministic_algorithms(True) # For PyTorch 1.8+

# Gá»i hÃ m set_seed vá»›i má»™t sá»‘ báº¥t ká»³
set_seed(42) # Báº¡n cÃ³ thá»ƒ chá»n báº¥t ká»³ sá»‘ nguyÃªn nÃ o
# DÃ¹ng ResNet18 Ä‘Ã£ tiá»n huáº¥n luyá»‡n Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng
resnet = resnet18(pretrained=True)
resnet = torch.nn.Sequential(*list(resnet.children())[:-1])  # Bá» lá»›p FC cuá»‘i cÃ¹ng
resnet.eval()
# Khá»Ÿi táº¡o mÃ´ hÃ¬nh
model = CNNLSTM_ImageRadFusion(input_dim=513, hidden_dim=128)

# Load trá»ng sá»‘
try:
    model.load_state_dict(torch.load("best_model_1.pth", map_location=torch.device('cpu')))
    model.eval()
except Exception as e:
    st.error(f"âŒ KhÃ´ng thá»ƒ load model: {e}")
    st.stop()

# Táº¡o projector tá»« 12288 â†’ 512
projector = torch.nn.Linear(12288, 512)

# HÃ m tiá»n xá»­ lÃ½ áº£nh
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

# Giao diá»‡n Streamlit
st.title("ğŸ“¸ Dá»± bÃ¡o bá»©c xáº¡ máº·t trá»i tá»« áº£nh")

uploaded_files = st.file_uploader("Táº£i lÃªn chuá»—i áº£nh (theo thá»© tá»± thá»i gian)", 
                                   type=["jpg", "png", "jpeg"], accept_multiple_files=True)

if uploaded_files:
    st.subheader("áº¢nh Ä‘Ã£ táº£i lÃªn:")
    cols = st.columns(min(5, len(uploaded_files)))
    for i, file in enumerate(uploaded_files):
        image = Image.open(file)
        cols[i % 5].image(image, width=100, caption=f"áº¢nh {i+1}")

    if st.button("ğŸ“ˆ Dá»± Ä‘oÃ¡n tá»« áº£nh"):
        try:
            tensors = []
            for file in uploaded_files:
                img = Image.open(file).convert("RGB")
                img_tensor = transform(img).unsqueeze(0)  # (1, 3, 224, 224)
                with torch.no_grad():
                    feature = resnet(img_tensor)           # (1, 512, 1, 1)
                    feature = feature.view(-1)             # (512,)
                    tensors.append(feature)

            # Stack láº¡i thÃ nh chuá»—i (T, 512)
            image_features = torch.stack(tensors)  # (T, 512)

            # ThÃªm 1 Ä‘áº·c trÆ°ng bá»©c xáº¡ giáº£
            rad_dummy = torch.zeros(image_features.size(0), 1)
            combined_input = torch.cat((image_features, rad_dummy), dim=1)  # (T, 513)
            input_tensor = combined_input.unsqueeze(0)  # (1, T, 513)


            # ThÃªm batch dim â†’ (1, T, 513)
            input_tensor = combined_input.unsqueeze(0)

            with torch.no_grad():
                output = model(input_tensor)
                prediction = output.item()*10

            st.subheader("ğŸŒ Dá»± bÃ¡o bá»©c xáº¡ máº·t trá»i:")
            st.success(f"ğŸŒ¤ï¸ GiÃ¡ trá»‹ bá»©c xáº¡ dá»± Ä‘oÃ¡n: **{prediction:.2f} W/mÂ²**")

        except Exception as e:
            st.error(f"âŒ Lá»—i dá»± Ä‘oÃ¡n: {e}")
